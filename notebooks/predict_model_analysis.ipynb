{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First level model predictions analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, (Path(\".\").resolve().parent / \"common\").as_posix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_PATH = Path(\".\").resolve().parent / \"input/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "\n",
    "from albumentations import Compose, RandomCrop, RandomCropNearBBox, ShiftScaleRotate, GaussNoise, ElasticTransform\n",
    "from albumentations import CenterCrop, Rotate, RandomRotate90, Flip\n",
    "from albumentations.pytorch import ToTensor\n",
    "\n",
    "\n",
    "from dataflow.datasets import HPADataset\n",
    "from dataflow.dataloaders import get_base_train_val_loaders_by_fold, get_train_val_indices, Subset, TransformedDataset, DataLoader\n",
    "from models.resnet import HPAResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 12\n",
    "device = \"cuda\"\n",
    "debug = False\n",
    "\n",
    "val_fold_index = 0\n",
    "n_folds = 3\n",
    "\n",
    "n_tta = 4\n",
    "\n",
    "tta_transforms = Compose([\n",
    "    Flip(),\n",
    "    RandomRotate90(),\n",
    "    CenterCrop(320, 320),\n",
    "    ToTensor()\n",
    "])\n",
    "tta_transform_fn = lambda dp: tta_transforms(**{\"image\": dp[0], \"tags\": dp[1].astype('float32')})\n",
    "\n",
    "\n",
    "batch_size = 128\n",
    "num_workers = 8\n",
    "\n",
    "trainval_df = pd.read_csv(INPUT_PATH / \"train.csv\")\n",
    "trainval_ds = HPADataset(trainval_df, INPUT_PATH / \"train\")\n",
    "_, val_fold_indices = get_train_val_indices(trainval_df,\n",
    "                                            fold_index=val_fold_index,\n",
    "                                            n_splits=n_folds,\n",
    "                                            random_state=seed)\n",
    "\n",
    "\n",
    "val_ds = Subset(trainval_ds, val_fold_indices)\n",
    "val_ds = TransformedDataset(val_ds, transform_fn=tta_transform_fn)\n",
    "\n",
    "\n",
    "val_loader = DataLoader(val_ds, shuffle=False,\n",
    "                        batch_size=batch_size, num_workers=num_workers,\n",
    "                        pin_memory=\"cuda\" in device, drop_last=False)\n",
    "\n",
    "model = HPAResNet50(num_classes=HPADataset.num_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_uuid = \"6bf2701872df4bd190a9c517a5e52f32\"\n",
    "run_name = \"resnet50_val_acc_0.37\"\n",
    "\n",
    "weights_filename = \"model_HPAResNet50_162_val_loss=0.07056979.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_path(mlflow_client, run_uuid, weights_filename):\n",
    "    path = Path(client.tracking_uri) \n",
    "    run_info = client.get_run(run_id=run_uuid)\n",
    "    artifact_uri = run_info.info.artifact_uri\n",
    "    artifact_uri = artifact_uri[artifact_uri.find(\"/\") + 1:]\n",
    "    path /= Path(artifact_uri) / weights_filename\n",
    "    assert path.exists(), \"File is not found at {}\".format(path.as_posix())\n",
    "    return path.as_posix()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "client = mlflow.tracking.MlflowClient(tracking_uri=\"../output\")\n",
    "model.load_state_dict(torch.load(weights_path(client, run_uuid, weights_filename)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "_ = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from custom_ignite.metrics.accuracy import Accuracy\n",
    "from custom_ignite.metrics.precision import Precision\n",
    "from custom_ignite.metrics.recall import Recall\n",
    "from ignite.metrics import MetricsLambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_metric = Accuracy(is_multilabel=True)\n",
    "precision_metric = Precision(average=False, is_multilabel=True)\n",
    "recall_metric = Recall(average=False, is_multilabel=True)\n",
    "\n",
    "f1_metric = precision_metric * recall_metric * 2 / (recall_metric + precision_metric + 1e-20)\n",
    "f1_metric = MetricsLambda(lambda t: torch.mean(t).item(), f1_metric)\n",
    "\n",
    "metrics = {\n",
    "    \"accuracy\": accuracy_metric,\n",
    "    \"precision\": precision_metric,\n",
    "    \"recall\": recall_metric,\n",
    "    \"f1\": f1_metric\n",
    "}\n",
    "\n",
    "# Add Precision/Recall per tag\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "def thresholded_output_transform_per_tag(output, k):\n",
    "    y_pred, y = output\n",
    "    y_pred, y = y_pred[:, k], y[:, k]\n",
    "    y_pred = torch.round(torch.sigmoid(y_pred))\n",
    "    return y_pred, y\n",
    "\n",
    "\n",
    "for i, t in enumerate(HPADataset.tags):\n",
    "    metrics['pr_{}'.format(t)] = Precision(\n",
    "        output_transform=partial(thresholded_output_transform_per_tag, k=i)\n",
    "    )\n",
    "    metrics['re_{}'.format(t)] = Recall(\n",
    "        output_transform=partial(thresholded_output_transform_per_tag, k=i)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ignite.engine import create_supervised_evaluator, convert_tensor, Events, Engine\n",
    "from ignite.contrib.handlers import ProgressBar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_batch(batch, device=None, non_blocking=False):\n",
    "    \"\"\"Prepare batch for training: pass to a device with options\n",
    "\n",
    "    \"\"\"\n",
    "    x, y = batch['image'], batch['tags']\n",
    "    return (convert_tensor(x, device=device, non_blocking=non_blocking), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_tta = create_supervised_evaluator(model, device=device, non_blocking=\"cuda\" in device, prepare_batch=prepare_batch)\n",
    "ProgressBar(desc='Predict TTA', persist=True).attach(predictor_tta)\n",
    "\n",
    "\n",
    "y_probas_mean_tta = [0 for _ in range(len(val_loader))]\n",
    "y_true = []\n",
    "\n",
    "@predictor_tta.on(Events.ITERATION_COMPLETED)\n",
    "def save_tta_predictions(engine):\n",
    "    output = engine.state.output\n",
    "    iteration = (engine.state.iteration - 1) % len(val_loader)\n",
    "    y_probas = torch.sigmoid(output[0].detach())\n",
    "        \n",
    "    y_probas_mean_tta[iteration] += y_probas * 1.0 / n_tta\n",
    "\n",
    "    tta_index = engine.state.epoch - 1\n",
    "    if tta_index == 0:\n",
    "        y_true.append(output[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predict TTA[81/81] 100%|██████████ [00:31<00:00]\n",
      "Predict TTA[81/81] 100%|██████████ [00:31<00:00]\n",
      "Predict TTA[81/81] 100%|██████████ [00:32<00:00]\n",
      "Predict TTA[81/81] 100%|██████████ [00:32<00:00]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ignite.engine.engine.State at 0x7f6889d4bba8>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor_tta.run(val_loader, max_epochs=n_tta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds_mean_tta = [torch.round(y_probas).cpu() for y_probas in y_probas_mean_tta]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(engine, batch):\n",
    "    y_pred, y = batch\n",
    "    return y_pred, y\n",
    "\n",
    "\n",
    "validator = Engine(validate)\n",
    "ProgressBar(desc='Validation').attach(validator)\n",
    "\n",
    "for name, metric in metrics.items():\n",
    "    metric.attach(validator, name)\n",
    "\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "tags_counter = defaultdict(int)\n",
    "\n",
    "@validator.on(Events.ITERATION_COMPLETED)\n",
    "def count_tags(engine):\n",
    "    _, y = engine.state.output\n",
    "    for i, t in enumerate(HPADataset.tags):\n",
    "        tags_counter[t] += torch.sum(y[:, i]).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "text/plain": [
       "<ignite.engine.engine.State at 0x7f688a0400b8>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [(y_pred, y) for y_pred, y in zip(y_preds_mean_tta, y_true)]\n",
    "\n",
    "validator.run(data, max_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_score = validator.state.metrics['accuracy']\n",
    "pr_score = torch.mean(validator.state.metrics['precision']).item()\n",
    "re_score = torch.mean(validator.state.metrics['recall']).item()\n",
    "f1_score = validator.state.metrics['f1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.37253951323572193, 0.690301884353082, 0.586601053686286, 0.6110574725381293)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_score, pr_score, re_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8385391638635271"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validator.state.metrics['pr_{}'.format(HPADataset.tags[0])].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pr=0.8385 | Re=0.8126 | #=4295 - Actin filaments\n",
      "Pr=0.8987 | Re=0.6794 | #= 418 - Aggresome\n",
      "Pr=0.8815 | Re=0.6164 | #=1207 - Cell junctions\n",
      "Pr=0.8000 | Re=0.4769 | #= 520 - Centrosome\n",
      "Pr=0.8449 | Re=0.6065 | #= 620 - Cytokinetic bridge\n",
      "Pr=0.8082 | Re=0.3520 | #= 838 - Cytoplasmic bodies\n",
      "Pr=0.6993 | Re=0.2976 | #= 336 - Cytosol\n",
      "Pr=0.8149 | Re=0.5473 | #= 941 - Endoplasmic reticulum\n",
      "Pr=0.5000 | Re=0.0556 | #=  18 - Endosomes\n",
      "Pr=0.0000 | Re=0.0000 | #=  15 - Focal adhesion sites\n",
      "Pr=0.0000 | Re=0.0000 | #=  10 - Golgi apparatus\n",
      "Pr=0.7434 | Re=0.3096 | #= 365 - Intermediate filaments\n",
      "Pr=0.6250 | Re=0.1528 | #= 229 - Lipid droplets\n",
      "Pr=0.6531 | Re=0.1788 | #= 179 - Lysosomes\n",
      "Pr=0.8990 | Re=0.7753 | #= 356 - Microtubule ends\n",
      "Pr=0.0000 | Re=0.0000 | #=   7 - Microtubule organizing center\n",
      "Pr=0.0000 | Re=0.0000 | #= 177 - Microtubules\n",
      "Pr=0.4286 | Re=0.0429 | #=  70 - Mitochondria\n",
      "Pr=0.5294 | Re=0.0598 | #= 301 - Mitotic spindle\n",
      "Pr=0.6667 | Re=0.1255 | #= 494 - Nuclear bodies\n",
      "Pr=0.0000 | Re=0.0000 | #=  58 - Nuclear membrane\n",
      "Pr=0.7029 | Re=0.4623 | #=1259 - Nuclear speckles\n",
      "Pr=0.5765 | Re=0.1835 | #= 267 - Nucleoli\n",
      "Pr=0.8423 | Re=0.5885 | #= 989 - Nucleoli fibrillar center\n",
      "Pr=0.6800 | Re=0.1589 | #= 107 - Nucleoplasm\n",
      "Pr=0.6983 | Re=0.6219 | #=2743 - Peroxisomes\n",
      "Pr=0.0000 | Re=0.0000 | #= 109 - Plasma membrane\n",
      "Pr=0.0000 | Re=0.0000 | #=   3 - Rods & rings\n"
     ]
    }
   ],
   "source": [
    "for t in HPADataset.tags:\n",
    "    print(\"Pr={:.4f} | Re={:.4f} | #={:4} - {}\".format(validator.state.metrics['pr_{}'.format(t)], \n",
    "                                                       validator.state.metrics['re_{}'.format(t)], \n",
    "                                                       int(tags_counter[t]),\n",
    "                                                       t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "y_preds = np.random.randint(0, 2, size=(10, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0 1 3 4 6 8 12 13 15 16 17 21 24 25 26 27'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join([str(v) for v in np.where(y_preds[0, :] > 0)[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1,\n",
       "        0, 0, 1, 1, 1, 1],\n",
       "       [0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0,\n",
       "        1, 0, 0, 1, 1, 1],\n",
       "       [0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1,\n",
       "        1, 0, 1, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "        1, 0, 1, 1, 1, 1],\n",
       "       [0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1,\n",
       "        0, 1, 1, 0, 0, 1],\n",
       "       [1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 0, 0],\n",
       "       [1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "        0, 0, 1, 1, 0, 1],\n",
       "       [1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "        0, 0, 1, 0, 1, 0],\n",
       "       [1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0,\n",
       "        0, 1, 1, 0, 1, 1],\n",
       "       [0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "        1, 0, 1, 1, 1, 1]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
